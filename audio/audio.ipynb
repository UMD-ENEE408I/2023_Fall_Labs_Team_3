{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "from scipy import signal\n",
    "import pyaudio\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record(seconds):\n",
    "    frames1 = []\n",
    "    frames2 = []\n",
    "    for i in range(0, int(fs/chunk *seconds)):\n",
    "        data1 = stream1.read(chunk)\n",
    "        data2 = stream2.read(chunk)\n",
    "        for x in np.frombuffer(data1, dtype=np.int16):\n",
    "            frames1.append(x)\n",
    "        for x in np.frombuffer(data2, dtype=np.int16):\n",
    "            frames2.append(x)\n",
    "        frame1 = np.array(frames1)\n",
    "        frame2 = np.array(frames2)\n",
    "    return frame1, frame2\n",
    "def getDirection(m1, m2):\n",
    "    #get time diff\n",
    "    max = 0\n",
    "    sign = 1\n",
    "    index = 0\n",
    "    for i in range(len(m1)):\n",
    "        sum = np.sum(np.multiply(m1[0:i+1],m2[(len(m1)-1-i):len(m1)]))\n",
    "        if max < sum:\n",
    "            index = i\n",
    "            max = sum\n",
    "    for i in range(len(m1)):\n",
    "        sum = np.sum(np.multiply(m2[0:i+1],m1[(len(m1)-1-i):len(m1)]))\n",
    "        if max < sum:\n",
    "            index = i\n",
    "            max = sum\n",
    "            sign = -1\n",
    "\n",
    "    #delay = m2 shift\n",
    "    delay = (len(m1)-index-1)*sign\n",
    "    time_delay = delay/fs\n",
    "    x = time_delay*344/0.085\n",
    "    if(x > 1):\n",
    "        x = 1\n",
    "    if(x< -1):\n",
    "        x=-1\n",
    "    angle = np.arcsin(x)\n",
    "    return angle*57.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shenzhi\\2023_Fall_Labs_Team_3\\audio\\audio.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m stream2 \u001b[39m=\u001b[39m p2\u001b[39m.\u001b[39mopen(\u001b[39mformat\u001b[39m\u001b[39m=\u001b[39mpyaudio\u001b[39m.\u001b[39mpaInt16,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                 channels\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                 rate\u001b[39m=\u001b[39mfs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W2sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                 \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                 frames_per_buffer\u001b[39m=\u001b[39mchunk,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                 input_device_index\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m frame1, frame2 \u001b[39m=\u001b[39m record(\u001b[39m2\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(getDirection(frame1, frame2))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m plt\u001b[39m.\u001b[39msubplot(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(frame1)\n",
      "\u001b[1;32mc:\\Users\\shenzhi\\2023_Fall_Labs_Team_3\\audio\\audio.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         \u001b[39mmax\u001b[39m \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(m1)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W2sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39msum\u001b[39m \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msum(np\u001b[39m.\u001b[39;49mmultiply(m2[\u001b[39m0\u001b[39;49m:i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m],m1[(\u001b[39mlen\u001b[39;49m(m1)\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m-\u001b[39;49mi):\u001b[39mlen\u001b[39;49m(m1)]))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mmax\u001b[39m \u001b[39m<\u001b[39m \u001b[39msum\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         index \u001b[39m=\u001b[39m i\n",
      "File \u001b[1;32mc:\\Users\\shenzhi\\2023_Fall_Labs_Team_3\\Tutorial_2\\lab_env\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2310\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m   2311\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m-> 2313\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[0;32m   2314\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[1;32mc:\\Users\\shenzhi\\2023_Fall_Labs_Team_3\\Tutorial_2\\lab_env\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 88\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer() \n",
    "#audio\n",
    "chunk = 1024\n",
    "sample_format = pyaudio.paInt16\n",
    "channels = 1\n",
    "fs = 44100\n",
    "seconds = 0.5\n",
    "p1 = pyaudio.PyAudio()\n",
    "p2 = pyaudio.PyAudio()\n",
    "stream1 = p1.open(format=pyaudio.paInt16,\n",
    "                channels=1,\n",
    "                rate=44100,\n",
    "                input=True,\n",
    "                frames_per_buffer=chunk,\n",
    "                input_device_index=4)\n",
    "stream2 = p2.open(format=pyaudio.paInt16,\n",
    "                channels=1,\n",
    "                rate=fs,\n",
    "                input=True,\n",
    "                frames_per_buffer=chunk,\n",
    "                input_device_index=1) \n",
    "\n",
    "\n",
    "frame1, frame2 = record(2)\n",
    "print(getDirection(frame1, frame2))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(frame1)\n",
    "plt.title('1')\n",
    "plt.subplot(2,1,2)\n",
    "plt.title('2')\n",
    "plt.plot(frame2)\n",
    "stream1.stop_stream()\n",
    "stream1.close()\n",
    "p1.terminate()\n",
    "stream2.stop_stream()\n",
    "stream2.close()\n",
    "p2.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pyaudio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\shenzhi\\2023_Fall_Labs_Team_3\\audio\\audio.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m p \u001b[39m=\u001b[39m pyaudio\u001b[39m.\u001b[39mPyAudio()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m info \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39mget_host_api_info_by_index(\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/shenzhi/2023_Fall_Labs_Team_3/audio/audio.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m numdevices \u001b[39m=\u001b[39m info\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdeviceCount\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pyaudio' is not defined"
     ]
    }
   ],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "info = p.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "\n",
    "for i in range(0, numdevices):\n",
    "    if (p.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "        print(\"Input Device id \", i, \" - \", p.get_device_info_by_host_api_device_index(0, i).get('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
